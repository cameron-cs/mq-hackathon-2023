{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 16:52:09.996025: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/lib/python3.11/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.2 when it was built against 1.14.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "data = pd.read_excel(\"./upd_data.xlsx\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender\n",
    "data['Gender'] = data['Gender'].fillna(0).map({0: 'Unknown', 1: 'Male', 2: 'Female'})\n",
    "data = pd.get_dummies(data, columns=['Gender'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State\n",
    "data['State'].fillna(0, inplace=True)\n",
    "data = pd.get_dummies(data, columns=['State'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intervention Required\n",
    "data['Intervention Required'] = data['Intervention Required'].fillna(0).map({0: 'Unknown', 1: 'Yes', 2: 'No'})\n",
    "data = pd.get_dummies(data, columns=['Intervention Required'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates\n",
    "temp = []\n",
    "for i in range(len(data)):\n",
    "    temp.append(int(data[\"Claim_Finalised_Date\"][i].timestamp() - data[\"Date_of_Accident\"][i].timestamp()))\n",
    "    \n",
    "data[\"Accident_to_Claim_Time\"] = list(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you find your X\n",
    "data['How Do You Find Your Doctor?'] = data['How Do You Find Your Doctor?'].fillna(0).map({0: 'Unknown', 1: '1', 2: '2', 3: '3'})\n",
    "data = pd.get_dummies(data, columns=['How Do You Find Your Doctor?'], drop_first=False)\n",
    "\n",
    "data['How Do You Find Your Case Manager?'] = data['How Do You Find Your Case Manager?'].fillna(0).map({0: 'Unknown', 1: '1', 2: '2', 3: '3'})\n",
    "data = pd.get_dummies(data, columns=['How Do You Find Your Case Manager?'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the rare blanks\n",
    "data['Med_Cert_Capacity'].fillna(0, inplace=True)\n",
    "data['Med_cert_unfit_restricted_weekdays'].fillna(0, inplace=True)\n",
    "\n",
    "data['Payment_early_intervention_rehab'].fillna(0, inplace=True)\n",
    "data['Payment_medicolegal'].fillna(0, inplace=True)\n",
    "data['Payment_Rehab'].fillna(0, inplace=True)\n",
    "data['Payment_travel_accomodation'].fillna(0, inplace=True)\n",
    "data['Payment_weekly_compensation'].fillna(0, inplace=True)\n",
    "data['Work Status at Referral'].fillna(0, inplace=True)\n",
    "data['Other_Paid'].fillna(0, inplace=True)\n",
    "data[\"How are you going financially?\"].fillna(0, inplace=True)\n",
    "\n",
    "data[\"Unable to control the important things?\"].fillna(0, inplace=True)\n",
    "data[\"You felt that things were going your way\"].fillna(0, inplace=True)\n",
    "data[\"First Orebro Score\"].fillna(0, inplace=True)\n",
    "data[\"Orebro Musculoskeletal Pain Total\"].fillna(25, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropped\n",
    "data = data.dropna(subset = \"Fitness_week2\")\n",
    "data = data.dropna(subset = \"Total_Paid\")\n",
    "data = data.dropna(subset= \"Felt difficulties were piling up high?\")\n",
    "data.drop([\n",
    "    \"Are you seeing a Therapist?\",\n",
    "    \"Is therapy helpful for you?\",\n",
    "    \"Claim_Risk_Assessment\"\n",
    "    ], axis=1, inplace=True)\n",
    "\n",
    "data.drop(labels= \"Date_of_Accident\", axis=1, inplace=True)\n",
    "data.drop(labels= \"Claim_Finalised_Date\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(data.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_continuous(df, continuous_column):\n",
    "    X = df.drop(columns=[continuous_column]) \n",
    "    y = df[continuous_column] \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    return sklearn.metrics.mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_week(df, fitness_week_column):\n",
    "    df[fitness_week_column] = np.clip(data[fitness_week_column], 0, 3 - 1)\n",
    "\n",
    "    X = df.drop(fitness_week_column, axis=1)\n",
    "    y = df[fitness_week_column]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(X_train.shape[1],)), \n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5), \n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3), \n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_all(input):\n",
    "    return {\n",
    "        \"Net_total_incurred_MSE\": errors_continuous(input.copy(), \"Net_total_incurred\"),\n",
    "        \"Total_Paid_MSE\": errors_continuous(input.copy(), \"Total_Paid\"),\n",
    "        \"Other_Paid_MSE\": errors_continuous(input.copy(), \"Other_Paid\"),\n",
    "        \"Payment_medical_MSE\": errors_continuous(input.copy(), \"Payment_medical\"),\n",
    "        \"Other_paid_risk_MSE\": errors_continuous(input.copy(), \"Other_paid_risk\"),\n",
    "        \"Fitness_week2_Acc\": predict_week(input.copy(), \"Fitness_week2\"),\n",
    "        \"Fitness_week6_Acc\": predict_week(input.copy(), \"Fitness_week6\"),\n",
    "        \"Fitness_week12_Acc\": predict_week(input.copy(), \"Fitness_week12\"),\n",
    "        \"Fitness_week26_Acc\": predict_week(input.copy(), \"Fitness_wekk26\"),\n",
    "        \"Fitness_week52_Acc\": predict_week(input.copy(), \"Fitness_week52\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 16:55:27.861417: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-11 16:55:27.877936: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-11 16:55:27.878080: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-11 16:55:27.880326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-11 16:55:27.880474: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-11 16:55:27.880573: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-11 16:55:27.926135: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-11 16:55:27.926296: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-11 16:55:27.926397: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-11 16:55:27.926480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4810 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2023-09-11 16:55:27.926744: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-09-11 16:55:28.684681: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dc9bc84450 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-11 16:55:28.684710: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2023-09-11 16:55:28.689393: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-09-11 16:55:28.700568: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2023-09-11 16:55:28.753428: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-11 16:55:28.802584: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 3ms/step - loss: 1.1295 - accuracy: 0.4565\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.8057 - accuracy: 0.5694\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6400\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.6376\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.7388\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.7059\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7694\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7576\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7671\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7953\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7570\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 1s 3ms/step - loss: 1.2333 - accuracy: 0.4235\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.7335 - accuracy: 0.7200\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.7365\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7718\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7671\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.8047\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8094\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8118\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8259\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3735 - accuracy: 0.8400\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8598\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 1s 3ms/step - loss: 0.8941 - accuracy: 0.6612\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8847\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8965\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.2567 - accuracy: 0.9200\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.2392 - accuracy: 0.9200\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1952 - accuracy: 0.9271\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1472 - accuracy: 0.9506\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1426 - accuracy: 0.9482\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1682 - accuracy: 0.9459\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1500 - accuracy: 0.9459\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9065\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 1s 3ms/step - loss: 0.8000 - accuracy: 0.6541\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2820 - accuracy: 0.9435\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2131 - accuracy: 0.9482\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2015 - accuracy: 0.9506\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1388 - accuracy: 0.9553\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1036 - accuracy: 0.9718\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1030 - accuracy: 0.9718\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0849 - accuracy: 0.9788\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0948 - accuracy: 0.9694\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9906\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9626\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 1s 3ms/step - loss: 1.1005 - accuracy: 0.5600\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3126 - accuracy: 0.9553\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1975 - accuracy: 0.9624\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1625 - accuracy: 0.9624\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9647\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1342 - accuracy: 0.9694\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0979 - accuracy: 0.9765\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 0.9765\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9835\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9812\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2912 - accuracy: 0.9346\n"
     ]
    }
   ],
   "source": [
    "prediction_data = predict_on_all(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Net_total_incurred_MSE': 8695190.412833737, 'Total_Paid_MSE': 46649930.16917009, 'Other_Paid_MSE': 103497513.64712854, 'Payment_medical_MSE': 4978232.169598891, 'Other_paid_risk_MSE': 3936302.361803603, 'Fitness_week2_Acc': 0.7570093274116516, 'Fitness_week6_Acc': 0.8598130941390991, 'Fitness_week12_Acc': 0.9065420627593994, 'Fitness_week26_Acc': 0.9626168012619019, 'Fitness_week52_Acc': 0.9345794320106506}\n"
     ]
    }
   ],
   "source": [
    "print(prediction_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
